{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data, model_zoo\n",
    "import numpy as np\n",
    "import pickle\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import os\n",
    "import os.path as ospbce\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorboardX import SummaryWriter\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import sys\n",
    "sys.path.append('/home/danleh/graduation-project-2020-sonnefred/multi-head/')\n",
    "\n",
    "from model.discriminator import FCDiscriminator\n",
    "from util.Loss import MSE_loss, CE_Loss, CrossEntropy2d\n",
    "from model.res_deeplab_dn import ResNet_Deeplab\n",
    "from util.dataset_dn import Freiburg_Dataset\n",
    "from util import transform\n",
    "from util.util import AverageMeter, intersectionAndUnion\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4\n",
    "IGNORE_LABEL = 255\n",
    "INPUT_SIZE = '640,320'\n",
    "LEARNING_RATE = 2.5e-4\n",
    "LEARNING_RATE_D = 1e-5\n",
    "MOMENTUM = 0.9\n",
    "ALPHA = 0.9\n",
    "NUM_CLASSES = 14\n",
    "START_EPOCH = 0\n",
    "FIRST_EPOCH = 50\n",
    "EPOCHS = 150\n",
    "POWER = 0.9\n",
    "RANDOM_SEED = 1234\n",
    "RESTORE_FROM = '/data/models/multi-head/multitask_v2/trained_weights.pth'\n",
    "ROOT = '/data/freiburg/'\n",
    "#LOG_SAVE_PATH = '/home/jsun/Project/multi-head/logs/dn_v3/'\n",
    "#SNAPSHOT_DIR = '/home/jsun/Project/multi-head/snapshots/dn_v3/'\n",
    "#BEST_DIR = '/home/jsun/Project/multi-head/best/dn_v3/'\n",
    "WEIGHT_DECAY = 0.0005\n",
    "\n",
    "GPU = 0\n",
    "\n",
    "PATH_DNV3 = '/data/models/multi-head/dn_v3/trained_weights.pth'\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "IM_WIDTH=640\n",
    "IM_HEIGHT=320"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified Dataset which contains the same input images as dn_v3, but where the labels refer to the domain of the images. The dataset now only needs to be called per split (training/testing) & no longer separately for each domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(split=None, data_root=None):\n",
    "    data_list_day = os.path.join(data_root, 'train', 'day', 'file_list.txt')\n",
    "    data_list_night = os.path.join(data_root, 'train', 'night', 'file_list.txt')\n",
    "\n",
    "    if not os.path.isfile(data_list_day):\n",
    "        raise (RuntimeError(\"Image list file do not exist: \" + data_list_day + \"\\n\"))\n",
    "    if not os.path.isfile(data_list_night):\n",
    "        raise (RuntimeError(\"Image list file do not exist: \" + data_list_night + \"\\n\"))\n",
    "\n",
    "    image_label_list = []\n",
    "    \n",
    "    list_read_day = open(data_list_day).readlines()\n",
    "    list_read_night = open(data_list_night).readlines()\n",
    "    \n",
    "    \n",
    "    length80day=(0.8*list_read_day.__len__()).__round__()\n",
    "    length80night=(0.8*list_read_night.__len__()).__round__()\n",
    "\n",
    "    if split=='train':\n",
    "        start_day,start_night=0,0\n",
    "        end_day,end_night=length80day,length80night\n",
    "    else:\n",
    "        start_day,start_night=length80day+1,length80night+1\n",
    "        end_day,end_night=list_read_day.__len__(),list_read_night.__len__()\n",
    "    \n",
    "    for line in list_read_day[start_day:end_day]:\n",
    "        line = line.strip()\n",
    "        image_name_day = os.path.join(data_root, 'train', 'day', 'RGB', 'fl_rgb'+line+'.png').replace('\\\\', '/')\n",
    "        label_name_day= 'day'\n",
    "        item_day = (image_name_day, label_name_day)\n",
    "        image_label_list.append(item_day)\n",
    "    for line in list_read_night[start_night:end_night]:\n",
    "        line = line.strip()\n",
    "        image_name_night = os.path.join(data_root, 'train', 'night', 'RGB', 'fl_rgb'+line+'.png').replace('\\\\', '/')\n",
    "        label_name_night = 'night'\n",
    "        item_night = (image_name_night, label_name_night)\n",
    "        image_label_list.append(item_night)\n",
    "\n",
    "            \n",
    "    print(\"Checking image&label pair {} list done!\".format(split))\n",
    "    return image_label_list\n",
    "\n",
    "\n",
    "class Classifier_Dataset(data.Dataset):\n",
    "    def __init__(self, split, data_root=None, transform=None):\n",
    "        self.split = split\n",
    "        self.data_list = make_dataset(split, data_root)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path, label = self.data_list[index]\n",
    "        \n",
    "        img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = np.float32(img) / 255.0\n",
    "        img = cv2.resize(img,(640,320),interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img, nothing = self.transform(img, img[:,:,0])\n",
    "        \n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transform.Compose([\n",
    "    transform.RandomHorizontalFlip(),\n",
    "    transform.ToTensor(),\n",
    "    transform.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])])\n",
    "\n",
    "test_transform = transform.Compose([\n",
    "    transform.ToTensor(),\n",
    "    transform.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])])\n",
    "\n",
    "# create dataloader   \n",
    "train_data= Classifier_Dataset('train', ROOT, train_transform)\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "#train_night_loader = data.DataLoader(Freiburg_Dataset('train', ROOT, 'night', train_transform), batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "test_data = Classifier_Dataset('test', ROOT, train_transform)\n",
    "test_loader = data.DataLoader(test_data, batch_size=1, shuffle=True, num_workers=0, pin_memory=True)\n",
    "#test_data_night = Freiburg_Dataset('test', ROOT, 'night', test_transform)\n",
    "#test_loader_night = data.DataLoader(test_data_night, batch_size=1, shuffle=False, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dnClassifier(nn.Module):\n",
    "    def __init__(self, img_width, img_height):\n",
    "        super(dnClassifier, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=10, stride = 10)\n",
    "        self.maxpool1=nn.MaxPool2d(kernel_size=15)\n",
    "        self.fc1 = nn.Linear(40, 1)\n",
    "        \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        x = self.cnn1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width=IM_WIDTH\n",
    "img_height=IM_HEIGHT\n",
    "model=dnClassifier(img_width, img_height)\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day=True #0 for day, 1 for night\n",
    "loss_module = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "def train_model(model, optimizer, train_loader, loss_module, num_epochs=3):\n",
    "    # Set model to train mode\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for data_inputs, data_labels in train_loader:\n",
    "            for i in range(len(data_labels)):\n",
    "                if data_labels[i]=='day':\n",
    "                    data_labels[i]=0\n",
    "                else:\n",
    "                    data_labels[i]=1    #day label = 0, night label = 1\n",
    "\n",
    "            ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
    "            data_inputs = data_inputs.to(device)\n",
    "            data_labels=torch.FloatTensor(data_labels)\n",
    "            data_labels = data_labels.to(device)\n",
    "\n",
    "            ## Step 2: Run the model on the input data\n",
    "            preds = model(data_inputs)\n",
    "            preds = preds.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
    "\n",
    "            ## Step 3: Calculate the loss\n",
    "            loss = loss_module(preds, data_labels)\n",
    "            #print(loss.item(), preds, data_labels)\n",
    "            \n",
    "            ## Step 4: Perform backpropagation\n",
    "            # Before calculating the gradients, we need to ensure that they are all zero.\n",
    "            # The gradients would not be overwritten, but actually added to the existing ones.\n",
    "            optimizer.zero_grad()\n",
    "            # Perform backpropagation\n",
    "            loss.backward()\n",
    "\n",
    "            ## Step 5: Update the parameters\n",
    "            optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, optimizer, train_loader, loss_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = model.state_dict()\n",
    "torch.save(state_dict, \"Classifier_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader):\n",
    "    model.eval() # Set model to eval mode\n",
    "    true_preds, num_preds = 0., 0.\n",
    "\n",
    "    with torch.no_grad(): # Deactivate gradients for the following code\n",
    "        for data_inputs, data_labels in data_loader:\n",
    "            for i in range(len(data_labels)):\n",
    "                if data_labels[i]=='day':\n",
    "                    data_labels[i]=0\n",
    "                else:\n",
    "                    data_labels[i]=1    #day label = 0, night label = 1\n",
    "            data_labels=torch.FloatTensor(data_labels)\n",
    "\n",
    "            \n",
    "            # Determine prediction of model on dev set\n",
    "            data_inputs, data_labels = data_inputs.to(device), data_labels.to(device)\n",
    "            preds = model(data_inputs)\n",
    "            preds = preds.squeeze(dim=1)\n",
    "            preds = torch.sigmoid(preds) # Sigmoid to map predictions between 0 and 1\n",
    "            pred_labels = torch.round(preds) # round predictions to 0 and 1\n",
    "            pred_domain='day' if pred_labels==0 else 'night'\n",
    "            true_domain='day' if data_labels==0 else 'night'\n",
    "            #print(f'Prediction: {pred_domain}   \\t    Truth: {true_domain}')\n",
    "            #print(pred_labels, data_labels)\n",
    "\n",
    "            # Keep records of predictions for the accuracy metric (true_preds=TP+TN, num_preds=TP+TN+FP+FN)\n",
    "            true_preds += (pred_labels == data_labels).sum()\n",
    "            num_preds += data_labels.shape[0]\n",
    "\n",
    "    acc = true_preds / num_preds\n",
    "    print(f\"Accuracy of the model: {100.0*acc:4.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"Classifier_weights.pth\")\n",
    "same_model = dnClassifier(img_width, img_height)\n",
    "same_model.load_state_dict(state_dict)\n",
    "same_model.to(device)\n",
    "eval_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c15e930adea914fc9eebd921bbf45ef68588f2e353611c8597ede7a11f9a6b3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('py_37': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
